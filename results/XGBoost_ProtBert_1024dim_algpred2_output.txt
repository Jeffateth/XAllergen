XGBoost model chosen
algpred2 dataset chosen
âœ… Loaded: Train=(16120, 320), Test=(4030, 320)

ğŸ“‰ DummyClassifier (Stratified) on Training Set (CV):

ğŸ“Š Dummy ROC-AUC: 0.4991 Â± 0.0000

ğŸ” Hyperparameter Tuning with GridSearchCV...

Fitting 5 folds for each of 72 candidates, totalling 360 fits

ğŸ† Best Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100, 'subsample': 1.0}
ğŸ† Best CV ROC-AUC: 0.9973

ğŸ”’ Final Evaluation on Hold-Out Test Set...

âœ… Model saved to: XGBoost_ProtBert_1024dim_algpred2_xgboost_model.pkl
ğŸ§ª Final Test Set Metrics:
 - Accuracy     : 0.8174
 - Sensitivity  : 0.6541
 - Specificity  : 0.9806
 - ROC-AUC      : 0.9461
 - MCC          : 0.6716
 - F1-Score     : 0.7817
 - Precision    : 0.9713

ğŸ§¾ Confusion Matrix on Hold-Out Test Set:

          Predicted 0  Predicted 1
Actual 0         1976           39
Actual 1          697         1318

ğŸ§ª Y-Scrambling (sanity check) on Training Set...

ğŸ”€ Y-Scrambled ROC-AUC: 0.4922 Â± 0.0079
ğŸ‘‰ This should be near 0.5 if your real model learned something.
