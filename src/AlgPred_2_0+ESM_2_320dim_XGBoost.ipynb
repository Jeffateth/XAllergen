{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilcsg8tr0Nus",
    "outputId": "6b11ab8a-9c74-4ba9-f7fb-5b59a4090162"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading train_positive...\n",
      "Downloading train_negative...\n",
      "Downloading validation_positive...\n",
      "Downloading validation_negative...\n",
      "âœ… Saved cleaned dataset to 'algpred2_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# URLs from AlgPred 2.0\n",
    "datasets = {\n",
    "    \"train_positive\": (\n",
    "        \"https://webs.iiitd.edu.in/raghava/algpred2/datasets/train_positive.txt\",\n",
    "        1,\n",
    "    ),\n",
    "    \"train_negative\": (\n",
    "        \"https://webs.iiitd.edu.in/raghava/algpred2/datasets/train_negative.txt\",\n",
    "        0,\n",
    "    ),\n",
    "    \"validation_positive\": (\n",
    "        \"https://webs.iiitd.edu.in/raghava/algpred2/datasets/validation_positive.txt\",\n",
    "        1,\n",
    "    ),\n",
    "    \"validation_negative\": (\n",
    "        \"https://webs.iiitd.edu.in/raghava/algpred2/datasets/validation_negative.txt\",\n",
    "        0,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Parse FASTA format\n",
    "\n",
    "\n",
    "def parse_fasta(fasta_text, label):\n",
    "    sequences = []\n",
    "    current_id = None\n",
    "    current_seq = \"\"\n",
    "    for line in fasta_text.strip().splitlines():\n",
    "        line = line.strip()\n",
    "        if line.startswith(\">\"):\n",
    "            if current_id is not None:\n",
    "                sequences.append((current_id, current_seq, label))\n",
    "            current_id = line[1:]  # remove \">\"\n",
    "            current_seq = \"\"\n",
    "        else:\n",
    "            current_seq += line\n",
    "    if current_id and current_seq:\n",
    "        sequences.append((current_id, current_seq, label))\n",
    "    return sequences\n",
    "\n",
    "\n",
    "# Download and parse all files\n",
    "all_entries = []\n",
    "for name, (url, label) in datasets.items():\n",
    "    print(f\"Downloading {name}...\")\n",
    "    response = requests.get(url)\n",
    "    entries = parse_fasta(response.text, label)\n",
    "    all_entries.extend(entries)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_entries, columns=[\"id\", \"sequence\", \"label\"])\n",
    "df.to_csv(\"algpred2_cleaned.csv\", index=False)\n",
    "print(\"âœ… Saved cleaned dataset to 'algpred2_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "GWihiZlc0iLM",
    "outputId": "722d41fe-bb2a-4143-9267-6de6af7f8b49"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting fair-esm\n",
      "  Downloading fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fair-esm, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed fair-esm-2.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install fair-esm torch pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_Jv62ty0mrA",
    "collapsed": true,
    "outputId": "778a1e22-2458-4988-a7f1-e5b0c49097ed"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ” Resuming from algpred2_esm2_embeddings_temp.csv â€” 9668 entries already processed.\n",
      "âš™ï¸  Extracting embeddings using ESM-2... (10482 sequences remaining)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10482/10482 [03:25<00:00, 50.88it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Final embeddings saved to 'algpred2_esm2_embeddings.csv'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import esm\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"algpred2_cleaned.csv\")\n",
    "sequences = list(df[\"sequence\"])\n",
    "labels = list(df[\"label\"])\n",
    "ids = list(df[\"id\"])\n",
    "\n",
    "# Load ESM-2 model\n",
    "model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Output files\n",
    "temp_file = \"algpred2_esm2_embeddings_temp.csv\"\n",
    "final_file = \"algpred2_esm2_embeddings.csv\"\n",
    "\n",
    "# Already processed IDs (for resuming)\n",
    "if os.path.exists(temp_file):\n",
    "    processed_ids = set(pd.read_csv(temp_file, usecols=[\"id\"])[\"id\"])\n",
    "    print(\n",
    "        f\"ğŸ” Resuming from {temp_file} â€” {len(processed_ids)} entries already processed.\"\n",
    "    )\n",
    "else:\n",
    "    processed_ids = set()\n",
    "\n",
    "# Filter data\n",
    "remaining_data = [\n",
    "    (ids[i], sequences[i], labels[i])\n",
    "    for i in range(len(ids))\n",
    "    if ids[i] not in processed_ids\n",
    "]\n",
    "\n",
    "# Batch setup\n",
    "batch_size = 1\n",
    "write_header = not os.path.exists(temp_file)\n",
    "feature_dim = 320  # ESM-2 T6-8M has 320-dim embeddings\n",
    "fieldnames = [\"id\", \"label\"] + [f\"f{k}\" for k in range(feature_dim)]\n",
    "\n",
    "print(\n",
    "    f\"âš™ï¸  Extracting embeddings using ESM-2... ({len(remaining_data)} sequences remaining)\"\n",
    ")\n",
    "\n",
    "with open(temp_file, mode=\"a\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "\n",
    "    for i in tqdm(range(0, len(remaining_data), batch_size)):\n",
    "        batch = remaining_data[i : i + batch_size]\n",
    "        batch_ids = [x[0] for x in batch]\n",
    "        batch_seqs = [x[1] for x in batch]\n",
    "        batch_labels = [x[2] for x in batch]\n",
    "\n",
    "        batch_data = [(batch_ids[j], batch_seqs[j]) for j in range(len(batch_seqs))]\n",
    "        _, _, batch_tokens = batch_converter(batch_data)\n",
    "        batch_tokens = batch_tokens.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch_tokens, repr_layers=[6])\n",
    "            token_representations = outputs[\"representations\"][6]\n",
    "\n",
    "        rows = []\n",
    "        for j, (_, seq) in enumerate(batch_data):\n",
    "            representation = token_representations[j, 1 : len(seq) + 1].mean(0)\n",
    "            entry = {\n",
    "                \"id\": batch_ids[j],\n",
    "                \"label\": batch_labels[j],\n",
    "            }\n",
    "            for k in range(feature_dim):\n",
    "                entry[f\"f{k}\"] = representation[k].item()\n",
    "            rows.append(entry)\n",
    "\n",
    "        writer.writerows(rows)\n",
    "\n",
    "# Final save (copy temp file to final)\n",
    "os.replace(temp_file, final_file)\n",
    "print(f\"âœ… Final embeddings saved to '{final_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bbgdtsm87X__",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "333cbb38-0e54-4fd7-e4f0-35cda00d5e0b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     id  label        f0        f1        f2        f3        f4        f5  \\\n",
      "0  P_13      1 -0.109098 -0.185716  0.221519  0.117864  0.173010 -0.071297   \n",
      "1  P_14      1 -0.130675  0.124254  0.189468  0.133837  0.307256  0.215280   \n",
      "2  P_17      1 -0.047639  0.091741  0.206645  0.098816  0.142606 -0.018435   \n",
      "3  P_46      1 -0.186664  0.066537  0.203491  0.166804  0.384989 -0.193995   \n",
      "4  P_47      1 -0.181058  0.059647  0.199809  0.173464  0.381596 -0.214030   \n",
      "\n",
      "         f6        f7  ...      f310      f311      f312      f313      f314  \\\n",
      "0  0.091311  0.057937  ...  0.112632 -0.199612 -0.013409  0.179182  0.017290   \n",
      "1  0.131589 -0.020784  ...  0.039018  0.151819 -0.133527  0.132653  0.024618   \n",
      "2 -0.028555  0.027641  ...  0.051962  0.149907  0.026423  0.055061  0.119498   \n",
      "3 -0.038884 -0.133102  ...  0.195923 -0.055615 -0.194248  0.147510 -0.090668   \n",
      "4 -0.020568 -0.122544  ...  0.231452 -0.054589 -0.196715  0.168328 -0.080225   \n",
      "\n",
      "       f315      f316      f317      f318      f319  \n",
      "0 -0.021770 -0.041867  0.171428 -0.177973 -0.048538  \n",
      "1 -0.507335 -0.144002  0.207308 -0.060667  0.110069  \n",
      "2 -0.344593 -0.060167  0.207516 -0.047506  0.115069  \n",
      "3 -0.374307 -0.189865  0.233800 -0.024271  0.206882  \n",
      "4 -0.352165 -0.188643  0.246979 -0.049606  0.200419  \n",
      "\n",
      "[5 rows x 322 columns]\n",
      "(20150, 322)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"algpred2_esm2_embeddings.csv\")\n",
    "print(df.head())\n",
    "print(df.shape)  # Rows, features"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import xgboost as xgb\n",
    "import random\n",
    "\n",
    "# ====================================\n",
    "# Step 1: Load Data\n",
    "# ====================================\n",
    "df = pd.read_csv(\"algpred2_esm2_embeddings.csv\")\n",
    "\n",
    "feature_cols = [f\"f{i}\" for i in range(256)]  # Adjust if using larger model\n",
    "X = df[feature_cols].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# ====================================\n",
    "# Step 2: Create Final Test Set (10%)\n",
    "# ====================================\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, stratify=y, random_state=42\n",
    ")\n",
    "print(f\"ğŸ“ Train+Val size: {X_temp.shape}, Test size: {X_test.shape}\")\n",
    "\n",
    "# ====================================\n",
    "# Step 3: Dummy Classifier Baseline (on Train+Val)\n",
    "# ====================================\n",
    "print(\"\\nğŸ“‰ DummyClassifier (Stratified) on Train+Val:\\n\")\n",
    "dummy = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "dummy_aucs = []\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, val_idx in cv.split(X_temp, y_temp):\n",
    "    dummy.fit(X_temp[train_idx], y_temp[train_idx])\n",
    "    y_dummy_proba = dummy.predict_proba(X_temp[val_idx])[:, 1]\n",
    "    auc = roc_auc_score(y_temp[val_idx], y_dummy_proba)\n",
    "    dummy_aucs.append(auc)\n",
    "\n",
    "print(f\"ğŸ“Š Dummy ROC-AUC: {np.mean(dummy_aucs):.4f} Â± {np.std(dummy_aucs):.4f}\")\n",
    "\n",
    "# ====================================\n",
    "# Step 4: Cross-Validation on Train+Val (XGBoost)\n",
    "# ====================================\n",
    "print(\"\\nğŸš€ 5-Fold Cross-Validation (XGBoost) on Train+Val...\\n\")\n",
    "xgb_aucs = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_temp, y_temp)):\n",
    "    X_train, X_val = X_temp[train_idx], X_temp[val_idx]\n",
    "    y_train, y_val = y_temp[train_idx], y_temp[val_idx]\n",
    "\n",
    "    clf = xgb.XGBClassifier(\n",
    "        use_label_encoder=False, eval_metric=\"logloss\", random_state=42\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_val)\n",
    "    y_proba = clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_proba)\n",
    "    xgb_aucs.append(auc)\n",
    "\n",
    "    print(f\"ğŸ“‚ Fold {fold+1} AUC: {auc:.4f}\")\n",
    "    print(classification_report(y_val, y_pred, digits=4))\n",
    "    print(\"------\")\n",
    "\n",
    "print(f\"\\nâœ… Mean CV ROC-AUC: {np.mean(xgb_aucs):.4f} Â± {np.std(xgb_aucs):.4f}\")\n",
    "\n",
    "# ====================================\n",
    "# Step 5: Final Test Set Evaluation\n",
    "# ====================================\n",
    "print(\"\\nğŸ”’ Final Evaluation on Hold-Out Test Set...\\n\")\n",
    "clf_final = xgb.XGBClassifier(\n",
    "    use_label_encoder=False, eval_metric=\"logloss\", random_state=42\n",
    ")\n",
    "clf_final.fit(X_temp, y_temp)\n",
    "\n",
    "y_test_pred = clf_final.predict(X_test)\n",
    "y_test_proba = clf_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "print(f\"ğŸ¯ Final Test ROC-AUC: {test_auc:.4f}\")\n",
    "\n",
    "# ====================================\n",
    "# Step 6: Y-Scrambling Control\n",
    "# ====================================\n",
    "print(\"\\nğŸ§ª Y-Scrambling (sanity check) on Train+Val...\\n\")\n",
    "y_temp_scrambled = y_temp.copy()\n",
    "random.seed(42)\n",
    "random.shuffle(y_temp_scrambled)\n",
    "\n",
    "scrambled_aucs = []\n",
    "for train_idx, val_idx in cv.split(X_temp, y_temp_scrambled):\n",
    "    X_train, X_val = X_temp[train_idx], X_temp[val_idx]\n",
    "    y_train, y_val = y_temp_scrambled[train_idx], y_temp_scrambled[val_idx]\n",
    "\n",
    "    clf_scrambled = xgb.XGBClassifier(\n",
    "        use_label_encoder=False, eval_metric=\"logloss\", random_state=42\n",
    "    )\n",
    "    clf_scrambled.fit(X_train, y_train)\n",
    "    y_proba_scrambled = clf_scrambled.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_proba_scrambled)\n",
    "    scrambled_aucs.append(auc)\n",
    "\n",
    "print(\n",
    "    f\"ğŸ”€ Y-Scrambled ROC-AUC: {np.mean(scrambled_aucs):.4f} Â± {np.std(scrambled_aucs):.4f}\"\n",
    ")\n",
    "print(\"ğŸ‘‰ This should be near 0.5 if your real model learned something.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvQ6gYSmeMsx",
    "outputId": "9e230e2d-17e6-48b8-c75a-c17026d7c36f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ“ Train+Val size: (18135, 256), Test size: (2015, 256)\n",
      "\n",
      "ğŸ“‰ DummyClassifier (Stratified) on Train+Val:\n",
      "\n",
      "ğŸ“Š Dummy ROC-AUC: 0.4988 Â± 0.0048\n",
      "\n",
      "ğŸš€ 5-Fold Cross-Validation (XGBoost) on Train+Val...\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:37:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ“‚ Fold 1 AUC: 0.9955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9779    0.9768    0.9774      1813\n",
      "           1     0.9769    0.9779    0.9774      1814\n",
      "\n",
      "    accuracy                         0.9774      3627\n",
      "   macro avg     0.9774    0.9774    0.9774      3627\n",
      "weighted avg     0.9774    0.9774    0.9774      3627\n",
      "\n",
      "------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:37:58] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ“‚ Fold 2 AUC: 0.9950\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9750    0.9680    0.9715      1813\n",
      "           1     0.9683    0.9752    0.9717      1814\n",
      "\n",
      "    accuracy                         0.9716      3627\n",
      "   macro avg     0.9716    0.9716    0.9716      3627\n",
      "weighted avg     0.9716    0.9716    0.9716      3627\n",
      "\n",
      "------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:38:05] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ“‚ Fold 3 AUC: 0.9961\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9778    0.9724    0.9751      1813\n",
      "           1     0.9726    0.9779    0.9753      1814\n",
      "\n",
      "    accuracy                         0.9752      3627\n",
      "   macro avg     0.9752    0.9752    0.9752      3627\n",
      "weighted avg     0.9752    0.9752    0.9752      3627\n",
      "\n",
      "------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:38:12] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ“‚ Fold 4 AUC: 0.9964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9788    0.9653    0.9720      1814\n",
      "           1     0.9657    0.9790    0.9723      1813\n",
      "\n",
      "    accuracy                         0.9722      3627\n",
      "   macro avg     0.9722    0.9722    0.9722      3627\n",
      "weighted avg     0.9722    0.9722    0.9722      3627\n",
      "\n",
      "------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:38:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ“‚ Fold 5 AUC: 0.9951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9782    0.9653    0.9717      1814\n",
      "           1     0.9657    0.9785    0.9721      1813\n",
      "\n",
      "    accuracy                         0.9719      3627\n",
      "   macro avg     0.9720    0.9719    0.9719      3627\n",
      "weighted avg     0.9720    0.9719    0.9719      3627\n",
      "\n",
      "------\n",
      "\n",
      "âœ… Mean CV ROC-AUC: 0.9956 Â± 0.0005\n",
      "\n",
      "ğŸ”’ Final Evaluation on Hold-Out Test Set...\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:38:27] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9735    0.9841    0.9788      1008\n",
      "           1     0.9839    0.9732    0.9785      1007\n",
      "\n",
      "    accuracy                         0.9787      2015\n",
      "   macro avg     0.9787    0.9787    0.9787      2015\n",
      "weighted avg     0.9787    0.9787    0.9787      2015\n",
      "\n",
      "ğŸ¯ Final Test ROC-AUC: 0.9948\n",
      "\n",
      "ğŸ§ª Y-Scrambling (sanity check) on Train+Val...\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:38:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:38:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:39:00] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:39:10] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:39:19] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ”€ Y-Scrambled ROC-AUC: 0.5034 Â± 0.0048\n",
      "ğŸ‘‰ This should be near 0.5 if your real model learned something.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "v1qxkMygeYDt"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}